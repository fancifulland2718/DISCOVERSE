import os
import time
import shutil
import argparse
import traceback

import mink
import mujoco
import numpy as np
from scipy.spatial.transform import Rotation

import discoverse
from discoverse.envs import make_env
from discoverse import DISCOVERSE_ROOT_DIR, DISCOVERSE_ASSETS_DIR

from discoverse.universal_manipulation import UniversalTaskBase, PyavImageEncoder, recoder_single_arm

from discoverse.utils import (
    SimpleStateMachine, step_func, get_body_tmat
)

class UniversalRuntimeTaskExecutor:
    """é€šç”¨è¿è¡Œæ—¶ä»»åŠ¡æ‰§è¡Œå™¨
    
    é›†æˆäº†utilsæ¨¡å—ã€ç®€åŒ–çš„é”™è¯¯å¤„ç†ã€æ¨¡æ¿åŒ–é…ç½®æ”¯æŒ
    """

    def __init__(self, task: UniversalTaskBase, viewer, mj_model: mujoco.MjModel, 
                 mj_data: mujoco.MjData, robot_name: str, sync: bool = False):
        """åˆå§‹åŒ–è¿è¡Œæ—¶æ‰§è¡Œå™¨
        
        Args:
            task: UniversalTaskBaseä»»åŠ¡å®ä¾‹
            viewer: MuJoCo viewer
            mj_model: MuJoCoæ¨¡å‹
            mj_data: MuJoCoæ•°æ®
            robot_name: æœºæ¢°è‡‚åç§°
            sync: æ˜¯å¦å¯ç”¨å®æ—¶åŒæ­¥
        """
        self.task = task
        self.viewer = viewer
        self.mj_model = mj_model
        self.mj_data = mj_data
        self.renderer = mujoco.Renderer(mj_model)
        self.robot_name = robot_name
        self.sync = sync

        # æ—¶é—´å’Œé¢‘ç‡æ§åˆ¶
        self.sim_timestep = mj_model.opt.timestep
        self.viewer_fps = 60
        
        # ä»»åŠ¡é…ç½® - æ”¯æŒæ¨¡æ¿åŒ–é…ç½®
        self.resolved_states = task.task_config.get_resolved_states()
        self.total_states = len(self.resolved_states)

        # ä»ä»»åŠ¡é…ç½®è·å–æœºæ¢°è‡‚ç»´åº¦ä¿¡æ¯
        self.n_arm_joints = len(task.robot_interface.arm_joints)  # æœºæ¢°è‡‚å…³èŠ‚æ•°
        self.gripper_ctrl_idx = self.n_arm_joints  # å¤¹çˆªæ§åˆ¶ç´¢å¼•åœ¨æœºæ¢°è‡‚å…³èŠ‚ä¹‹å

        # å…³èŠ‚sensorç´¢å¼•
        self.joint_pos_sensor_idx = [
            mujoco.mj_name2id(
                mj_model, 
                mujoco.mjtObj.mjOBJ_SENSOR, 
                sensor_name
            ) 
            for sensor_name in task.robot_interface.joint_pos_sensors
        ]
        print(f"ğŸ” å…³èŠ‚ä½ç½®ä¼ æ„Ÿå™¨: {task.robot_interface.joint_pos_sensors}")
        print(f"ğŸ” å…³èŠ‚ä½ç½®ä¼ æ„Ÿå™¨ç´¢å¼•: {self.joint_pos_sensor_idx}")

        self.mujoco_ctrl_dim = mj_model.nu
        self.move_speed = 1.5  # æ§åˆ¶é€Ÿåº¦
        self.max_time = 20.0  # æœ€å¤§æ‰§è¡Œæ—¶é—´ï¼ˆä»¿çœŸæ—¶é—´ï¼ŒéçœŸå®æ—¶é—´ï¼‰

        self.task.randomizer.set_viewer(viewer)
        self.task.randomizer.set_renderer(self.renderer)

        self.record_frq = self.task.task_config.record_fps
        self.camera_cfgs = {cam['name']: cam for cam in self.task.task_config.camera_configs}

        self.camera_encoders = {}

        # self.reset(random=False)
        self.reset()

    def get_current_qpos(self):
        """è·å–å½“å‰å…³èŠ‚ä½ç½®"""
        return self.mj_data.qpos.copy()
    
    def check_action_done(self):
        """æ£€æŸ¥åŠ¨ä½œæ˜¯å¦å®Œæˆ"""
        current_qpos = self.get_current_qpos()
        # åªæ£€æŸ¥æœºæ¢°è‡‚å…³èŠ‚
        position_error = np.linalg.norm(current_qpos[:self.n_arm_joints] - self.target_control[:self.n_arm_joints])
        position_done = position_error < 0.02  # 2cmå®¹å·®
        
        # æ£€æŸ¥å»¶æ—¶æ¡ä»¶
        if self.current_delay > 0 and self.delay_start_sim_time is not None:
            delay_elapsed = self.mj_data.time - self.delay_start_sim_time
            delay_done = delay_elapsed >= self.current_delay
            if not delay_done:
                return False  # å»¶æ—¶æœªå®Œæˆï¼ŒåŠ¨ä½œæœªå®Œæˆ
            
        return position_done

    def get_observation(self):
        """è·å–å½“å‰è§‚æµ‹"""
        obs = {
            "time": self.mj_data.time,
            "jq" : self.mj_data.sensordata[self.joint_pos_sensor_idx].tolist(),
            "action": self.action[:self.mujoco_ctrl_dim].tolist(),
            "img" : {}
        }
        for camera_name in self.camera_cfgs.keys():
            self.set_renderer_size(self.camera_cfgs[camera_name]['width'], self.camera_cfgs[camera_name]['height'])
            obs["img"][camera_name] = self.get_rgb_image(camera_name).copy()
        return obs

    def get_rgb_image(self, camera_name):
        self.renderer.update_scene(self.mj_data, camera_name)
        return self.renderer.render()

    def set_renderer_size(self, width, height):
        self.renderer._width = width
        self.renderer._height = height
        self.renderer._rect.width = width
        self.renderer._rect.height = height

    def set_target_from_primitive(self, state_config):
        """ä½¿ç”¨åŸè¯­è®¾ç½®ç›®æ ‡æ§åˆ¶ä¿¡å·"""
        try:
            primitive = state_config["primitive"]
            params = state_config.get("params", {})
            gripper_state = state_config.get("gripper_state", "open")
            
            if primitive == "move_to_object":
                # ä½¿ç”¨åŸè¯­è®¡ç®—ç›®æ ‡ä½ç½®
                object_name = params.get("object_name", "")
                offset = np.array(params.get("offset", [0, 0, 0]))
                
                if object_name:
                    # è·å–ç‰©ä½“ä½ç½®
                    object_tmat = get_body_tmat(self.mj_data, object_name)
                    target_pos = object_tmat[:3, 3] + offset
                    
                    # è·å–å½“å‰æœ«ç«¯æ‰§è¡Œå™¨å§¿æ€çŸ©é˜µï¼ˆä»MuJoCoæ•°æ®ç›´æ¥è¯»å–ï¼‰
                    site_name = self.task.robot_interface.robot_config.end_effector_site
                    site_id = mujoco.mj_name2id(self.mj_model, mujoco.mjtObj.mjOBJ_SITE, site_name)
                    target_rmat = self.mj_data.site_xmat[site_id].reshape(3, 3).copy()
                    
                    # è·å–å®Œæ•´çš„qpos (åŒ…å«æ‰€æœ‰è‡ªç”±åº¦)
                    full_current_qpos = self.mj_data.qpos.copy()

                    # æ±‚è§£IK
                    solution, converged, solve_info = self.task.robot_interface.ik_solver.solve_ik(
                        target_pos, target_rmat, full_current_qpos
                    )
                    
                    if converged:
                        # IKæ±‚è§£å™¨è¿”å›æœºæ¢°è‡‚å…³èŠ‚è§£
                        self.target_control[:self.n_arm_joints] = solution[:self.n_arm_joints]
                        self.set_mocap_target("target", target_pos, Rotation.from_matrix(target_rmat).as_quat()[[3,0,1,2]])
                    else:
                        return False
                        
            elif primitive == "move_relative":
                offset = np.array(params.get("offset", [0, 0, 0]))
               
                site_name = self.task.robot_interface.robot_config.end_effector_site
                site_id = mujoco.mj_name2id(self.mj_model, mujoco.mjtObj.mjOBJ_SITE, site_name)
                current_pos = self.mj_data.site_xpos[site_id].copy()
                target_rmat = self.mj_data.site_xmat[site_id].reshape(3, 3).copy()
                
                target_pos = current_pos + offset
                
                full_current_qpos = self.mj_data.qpos.copy()
                
                solution, converged, solve_info = self.task.robot_interface.ik_solver.solve_ik(
                    target_pos, target_rmat, full_current_qpos
                )
                
                if converged:
                    self.target_control[:self.n_arm_joints] = solution[:self.n_arm_joints]
                    self.set_mocap_target("target", target_pos, Rotation.from_matrix(target_rmat).as_quat()[[3,0,1,2]])
                else:
                    return False
           
            if gripper_state == "open":
                self.target_control[self.gripper_ctrl_idx] = self.task.robot_interface.gripper_controller.open()
            elif gripper_state == "close":
                self.target_control[self.gripper_ctrl_idx] = self.task.robot_interface.gripper_controller.close()
            
            current_ctrl = self.mj_data.ctrl[:self.mujoco_ctrl_dim].copy()
            dif = np.abs(current_ctrl - self.target_control)
            self.joint_move_ratio = dif / (np.max(dif) + 1e-6)
            
            return True
            
        except Exception as e:
            print(f"   âŒ åŸè¯­æ‰§è¡Œå¤±è´¥: {e}")
            traceback.print_exc()
            return False

    def set_mocap_target(self, target_name, target_pos, target_quat, box_color=(0,1,0,0.1)):
        """è®¾ç½®Mocapç›®æ ‡ä½ç½®å’Œå§¿æ€"""
        mocap_id = self.mj_model.body(target_name).mocapid
        if mocap_id >= 0:
            self.mj_data.mocap_pos[mocap_id] = target_pos
            self.mj_data.mocap_quat[mocap_id] = target_quat
            self.mj_model.geom(f'{target_name}_box').rgba = box_color

    def step(self, decimation=5):
        """å•æ­¥æ‰§è¡Œ - é«˜é¢‘ä¸»å¾ªç¯"""
        try:
            if self.stm.trigger():
                if self.stm.state_idx < self.total_states:
                    state_config = self.resolved_states[self.stm.state_idx]
                    self.current_delay = state_config.get("delay", 0.0)
                    
                    if not self.set_target_from_primitive(state_config):
                        print(f"   âŒ çŠ¶æ€ {self.stm.state_idx} è®¾ç½®å¤±è´¥")
                        return False
                        
                    if self.current_delay > 0:
                        self.delay_start_sim_time = self.mj_data.time
                else:
                    self.success = self.check_task_success()
                    self.running = False
                    return True
                    
            elif self.mj_data.time > self.max_time:
                self.running = False
                return False

            else:
                self.stm.update()
            
            if self.check_action_done():
                self.current_delay = 0.0
                self.delay_start_sim_time = None
                self.stm.next()
            
            for i in range(self.n_arm_joints):
                self.action[i] = step_func(
                    self.action[i], 
                    self.target_control[i], 
                    self.move_speed * float(decimation) * self.joint_move_ratio[i] * self.mj_model.opt.timestep
                )
            self.action[self.gripper_ctrl_idx] = self.target_control[self.gripper_ctrl_idx]
            
            self.mj_data.ctrl[:self.mujoco_ctrl_dim] = self.action[:self.mujoco_ctrl_dim]
            
            for _ in range(decimation):
                mujoco.mj_step(self.mj_model, self.mj_data)

            return True

        except Exception as e:
            print(f"âŒ æ­¥è¿›å¤±è´¥: {e}")
            self.running = False
            return False
    
    def check_task_success(self):
        """æ£€æŸ¥ä»»åŠ¡æˆåŠŸæ¡ä»¶"""
        return self.task.check_success()
    
    def run(self):
        """è¿è¡Œä»»åŠ¡ä¸»å¾ªç¯"""
        step_count = 0
        obs_lst = []
        last_report_time = time.time()
        
        if self.sync:
            real_start_time = time.time()
            expected_sim_time = 0.0
        
        last_render_time = 0.0
        
        while self.running:
            if not self.step():
                break
                
            step_count += 1

            # å®æ—¶åŒæ­¥æ§åˆ¶
            if self.sync:
                expected_sim_time = self.mj_data.time
                real_elapsed = time.time() - real_start_time
                sim_elapsed = expected_sim_time
                
                # å¦‚æœä»¿çœŸè·‘å¾—å¤ªå¿«ï¼Œç­‰å¾…å®é™…æ—¶é—´è¿½ä¸Š
                if sim_elapsed > real_elapsed:
                    sleep_time = sim_elapsed - real_elapsed
                    if sleep_time > 0:
                        time.sleep(sleep_time)

            # æ£€æŸ¥vieweræ˜¯å¦è¢«å…³é—­ - ä½¿ç”¨å®˜æ–¹API
            if self.viewer is not None:
                if not self.viewer.is_running():
                    print("ğŸ¬ æŸ¥çœ‹å™¨å·²å…³é—­ï¼Œé€€å‡ºç¨‹åº")
                    self.viewer_closed = True
                    self.running = False
                    return False
                
                # å®šæœŸåŒæ­¥æ˜¾ç¤ºï¼ˆé™ä½é¢‘ç‡é¿å…æ€§èƒ½é—®é¢˜ï¼‰
                if self.mj_data.time - last_render_time > (1.0 / self.viewer_fps):
                    self.viewer.sync()
                    last_render_time = self.mj_data.time
            
            if len(obs_lst) < self.mj_data.time * self.record_frq:
                obs = self.get_observation()
                imgs = obs.pop('img')
                for cam_id, img in imgs.items():
                    self.camera_encoders[cam_id].encode(img, obs["time"])
                obs_lst.append(obs)

            # æ¯ç§’æŠ¥å‘Šä¸€æ¬¡è¿›åº¦
            if time.time() - last_report_time > 1.0:
                elapsed = time.time() - self.start_time
                sim_time_info = f", ä»¿çœŸæ—¶é—´: {self.mj_data.time:.1f}s" if self.sync else ""
                print(f"   â±ï¸  è¿è¡Œæ—¶é—´: {elapsed:.1f}s, æ­¥æ•°: {step_count}, å½“å‰çŠ¶æ€: {self.stm.state_idx+1}/{self.total_states}{sim_time_info}")
                last_report_time = time.time()

        # æŠ¥å‘Šç»“æœ
        elapsed_time = time.time() - self.start_time
        print(f"\\nğŸ“Š {self.robot_name.upper()}è¿è¡Œæ¶æ„æ‰§è¡Œå®Œæˆ!")
        print(f"   æ€»æ—¶é—´: {elapsed_time:.2f}s")
        print(f"   ä»¿çœŸæ—¶é—´: {self.mj_data.time:.2f}s")
        print(f"   æ€»æ­¥æ•°: {step_count}")
        print(f"   å®ŒæˆçŠ¶æ€: {self.stm.state_idx}/{self.total_states}")
        print(f"   ä»»åŠ¡æˆåŠŸ: {'âœ… æ˜¯' if self.success else 'âŒ å¦'}")
        if self.sync:
            time_ratio = self.mj_data.time / elapsed_time if elapsed_time > 0 else 0
            print(f"   æ—¶é—´æ¯”ä¾‹: {time_ratio:.2f} (ä»¿çœŸæ—¶é—´/çœŸå®æ—¶é—´)")

        for ec in self.camera_encoders.values():
            ec.close()
        
        if not self.success:
            shutil.rmtree(self.save_dir, ignore_errors=True)
            print(f"   âŒ ä»»åŠ¡æœªæˆåŠŸï¼Œå·²åˆ é™¤ä¿å­˜ç›®å½•: {self.save_dir}")
        else:
            # ä¿å­˜è§‚æµ‹æ•°æ®
            recoder_single_arm(self.save_dir, obs_lst)
            print(f"   è§‚æµ‹æ•°æ®å·²ä¿å­˜åˆ°: {self.save_dir}")

        return self.success
    
    def reset(self, random=True):
        """é‡ç½®ç¯å¢ƒå’Œæ‰§è¡Œå™¨çŠ¶æ€"""
        # é‡ç½®åˆ°homeä½ç½®
        mujoco.mj_resetDataKeyframe(self.mj_model, self.mj_data, self.mj_model.key(0).id)
        mujoco.mj_forward(self.mj_model, self.mj_data)

        # é‡æ–°åˆå§‹åŒ–mocap target
        mink.move_mocap_to_frame(self.mj_model, self.mj_data, "target", "endpoint", "site")

        # åº”ç”¨åœºæ™¯éšæœºåŒ–
        if random:
            self.task.randomize_scene()
        
        # é‡ç½®çŠ¶æ€æœº
        self.stm = SimpleStateMachine()
        self.stm.max_state_cnt = self.total_states
        
        # é‡ç½®æ§åˆ¶çŠ¶æ€
        self.target_control = np.zeros(self.mujoco_ctrl_dim)
        self.action = np.zeros(self.mujoco_ctrl_dim)
        self.joint_move_ratio = np.ones(self.mujoco_ctrl_dim)
        
        # é‡ç½®è¿è¡Œæ—¶çŠ¶æ€
        self.running = True
        self.start_time = time.time()
        self.success = False
        self.viewer_closed = False  # é‡ç½®viewerå…³é—­æ ‡å¿—
        
        # é‡ç½®å»¶æ—¶çŠ¶æ€
        self.current_delay = 0.0
        self.delay_start_sim_time = None
        
        # é‡æ–°åˆå§‹åŒ–åŠ¨ä½œ
        self.action[:] = self.get_current_qpos()[:self.mujoco_ctrl_dim]
        
        self.save_dir = os.path.join(DISCOVERSE_ROOT_DIR, "data", f"{self.robot_name}_{self.task.task_config.task_name}")
        os.makedirs(self.save_dir, exist_ok=True)

        self.camera_encoders = {}
        for cam_name in self.camera_cfgs.keys():
            if mujoco.mj_name2id(self.mj_model, mujoco.mjtObj.mjOBJ_CAMERA, cam_name) < 0:
                # raise ValueError(f"Camera '{cam_name}' not found in the MJCF model.")
                print(f"Camera '{cam_name}' not found in the MJCF model.")
            else:
                # fovy = self.camera_cfgs[cam_name].get("fovy", None)
                # if fovy:
                #     mj_model.cam(cam_name).fovy = fovy
                self.camera_encoders[cam_name] = PyavImageEncoder(
                    self.camera_cfgs[cam_name]["width"], 
                    self.camera_cfgs[cam_name]["height"], 
                    self.save_dir, 
                    cam_name
                )

def generate_robot_task_model(robot_name, task_name):
    """ç”ŸæˆæŒ‡å®šæœºæ¢°è‡‚çš„ä»»åŠ¡æ¨¡å‹"""
    xml_path = os.path.join(DISCOVERSE_ASSETS_DIR, "mjcf/tmp", f"{robot_name}_{task_name}.xml")
    make_env(robot_name, task_name, xml_path)
    return xml_path

def create_simple_visualizer(mj_model, mj_data):
    """åˆ›å»ºMuJoCoå†…ç½®å¯è§†åŒ–å™¨"""
    import mujoco.viewer
    viewer = mujoco.viewer.launch_passive(mj_model, mj_data)
    if mj_model.ncam > 0:
        viewer.cam.fixedcamid = 0  # ä½¿ç”¨id=0çš„ç›¸æœº
        viewer.cam.type = mujoco.mjtCamera.mjCAMERA_FIXED
    return viewer

def main(robot_name="airbot_play", task_name="place_block", sync=False, once=False, headless=False):
    """
    Args:
        robot_name: æœºæ¢°è‡‚åç§°
        task_name: ä»»åŠ¡åç§°
        sync: å®æ—¶åŒæ­¥
        once: å•æ¬¡æ‰§è¡Œ
        headless: æ— å¤´æ¨¡å¼
    """
    print(f"Welcome to discoverse {discoverse.__version__} !")
    print(discoverse.__logo__)

    xml_path = generate_robot_task_model(robot_name, task_name)
    mj_model = mujoco.MjModel.from_xml_path(xml_path)
    mj_data = mujoco.MjData(mj_model)
    
    # åˆ›å»ºæŸ¥çœ‹å™¨ï¼ˆé™¤éæ˜¯æ— å¤´æ¨¡å¼ï¼‰
    viewer = None if headless else create_simple_visualizer(mj_model, mj_data)

    # åˆ›å»ºé€šç”¨ä»»åŠ¡ - ä½¿ç”¨é¢„å¤„ç†çš„é…ç½®
    configs_root = os.path.join(DISCOVERSE_ROOT_DIR, "discoverse", "configs")
    robot_config_path = os.path.join(configs_root, "robots", f"{robot_name}.yaml")
    task_config_path = os.path.join(configs_root, "tasks", f"{task_name}.yaml")
    
    # ç›´æ¥åˆ›å»ºä»»åŠ¡å®ä¾‹ï¼Œä¼ é€’é¢„å¤„ç†çš„é…ç½®
    task = UniversalTaskBase(
        robot_config_path=robot_config_path,
        task_config_path=task_config_path,
        mj_model=mj_model,
        mj_data=mj_data
    )

    # åˆ›å»ºé€šç”¨è¿è¡Œæ—¶æ‰§è¡Œå™¨
    try:
        executor = UniversalRuntimeTaskExecutor(task, viewer, mj_model, mj_data, robot_name, sync)

        task_count = 0
       
        while True:
            task_count += 1
            print(f"\n{'='*50}")
            print(f"ğŸ¯ ç¬¬ {task_count} è½®ä»»åŠ¡å¼€å§‹")
            print(f"{'='*50}")
            
            # è¿è¡Œä»»åŠ¡
            success = executor.run()
            
            if success:
                print(f"\nğŸ‰ ç¬¬ {task_count} è½®ä»»åŠ¡æˆåŠŸå®Œæˆ!")
                print(f"   ä»»åŠ¡ç›®æ ‡å·²è¾¾æˆ")
            else:
                print(f"\nâš ï¸ ç¬¬ {task_count} è½®ä»»åŠ¡æœªå®Œå…¨æˆåŠŸ")
            
            # å•æ¬¡æ‰§è¡Œæ¨¡å¼ä¸‹ç›´æ¥é€€å‡º
            if once:
                break
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦é€€å‡ºå¾ªç¯
            if executor.viewer_closed:
                break
            
            # é‡ç½®ç¯å¢ƒå‡†å¤‡ä¸‹ä¸€è½®
            executor.reset()
        
    except Exception as e:
        print(f"âŒ è¿è¡Œæ—¶æ‰§è¡Œå¤±è´¥: {e}")
        traceback.print_exc()

    finally:
        # å…³é—­æŸ¥çœ‹å™¨
        if viewer is not None:
            try:
                viewer.close()
                print("ğŸ¬ æŸ¥çœ‹å™¨å·²å…³é—­")
            except:
                pass

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="é€šç”¨æœºæ¢°è‡‚ä»»åŠ¡æ¼”ç¤º")
    parser.add_argument("-r", "--robot", type=str, default="airbot_play", help="é€‰æ‹©æœºæ¢°è‡‚ç±»å‹", 
                       choices=["airbot_play", "arx_x5", "arx_l5", "piper", "panda", "rm65", "xarm7", "iiwa14", "ur5e"])
    parser.add_argument("-t", "--task", type=str, default="place_block", help="é€‰æ‹©ä»»åŠ¡ç±»å‹",
                       choices=["place_block", "cover_cup", "stack_block", "place_kiwi_fruit", "place_coffeecup", "close_laptop"])
    parser.add_argument("-s", "--sync", action="store_true", help="å¯ç”¨å®æ—¶åŒæ­¥æ¨¡å¼ï¼ˆä»¿çœŸæ—¶é—´ä¸çœŸå®æ—¶é—´ä¸€è‡´ï¼‰")
    parser.add_argument("-1", "--once", action="store_true", help="å•æ¬¡æ‰§è¡Œæ¨¡å¼ï¼ˆé»˜è®¤ä¸ºå¾ªç¯æ‰§è¡Œï¼‰")
    parser.add_argument("--headless", action="store_true", help="æ— å¤´æ¨¡å¼è¿è¡Œï¼ˆCICDæµ‹è¯•ç”¨ï¼‰")
    args = parser.parse_args()

    main(args.robot, args.task, sync=args.sync, once=args.once, headless=args.headless)
